{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation Tutorial using LLaMA and Mixtral\n",
    "\n",
    "This tutorial demonstrates how to use SDG repository to generate synthetic question-answer pairs from documents using large language models like LLaMA 3.3 70B. We will also generate data using Mixtral model for comparison. We'll cover:\n",
    "\n",
    "1. Setting up the environment\n",
    "2. Connecting to LLM servers\n",
    "3. Configuring the data generation pipeline\n",
    "4. Generating data with different models\n",
    "5. Comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Enable auto-reloading of modules - useful during development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Instructions\n",
    "\n",
    "Before running this notebook, you'll need to:\n",
    "\n",
    "```bash \n",
    "pip install git+https://github.com/Red-Hat-AI-Innovation-Team/sdg_hub.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "# datasets: For handling our data\n",
    "# OpenAI: For interfacing with the LLM servers\n",
    "# SDG components: For building our data generation pipeline\n",
    "from datasets import load_dataset, Dataset\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from sdg_hub.flow import Flow\n",
    "from sdg_hub.pipeline import Pipeline\n",
    "from sdg_hub.sdg import SDG\n",
    "from sdg_hub.registry import PromptRegistry\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up LLaMA 3.3 70B Model\n",
    "\n",
    "First, we need to host the LLaMA model using vLLM. This creates an OpenAI-compatible API endpoint.\n",
    "\n",
    "1. Start the vLLM server (run in terminal):\n",
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m vllm.entrypoints.openai.api_server \\\n",
    "    --model meta-llama/Llama-3.3-70B-Instruct \\\n",
    "    --dtype float16 \\\n",
    "    --tensor-parallel-size 8 \n",
    "```\n",
    "\n",
    "2. Connect to the model using OpenAI client below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5c1f0a242df0a53f6de3ed04a799f31c'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:42:54] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">GET</span>                                                               <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-3-70b-instruct/v1/models</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:42:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mGET\u001b[0m                                                               \u001b]8;id=943084;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=229656;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-3-70b-instruct/v1/models\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                     \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to model: meta-llama/llama-3-3-70b-instruct\n"
     ]
    }
   ],
   "source": [
    "# Configure OpenAI client to connect to our local vLLM server\n",
    "# endpoint = f\"http://localhost:8000/v1\"\n",
    "endpoint_llama3 = f\"https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3-3-70b-instruct/v1\"\n",
    "endpoint_mixtral = f\"https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral-8x7b-instruct-v01/v1\"\n",
    "openai_api_key = \"EMPTY\"  # vLLM doesn't require real API key\n",
    "openai_api_base = endpoint_llama3\n",
    "load_dotenv()\n",
    "display(os.environ['RITS_API_KEY'])\n",
    "default_headers={'RITS_API_KEY': os.environ['RITS_API_KEY']}\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    "    default_headers=default_headers,\n",
    ")\n",
    "\n",
    "# Verify we can see the model\n",
    "teacher_model = client.models.list().data[0].id\n",
    "print(f\"Connected to model: {teacher_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure LLaMA 3.3 Prompt Template\n",
    "\n",
    "We need to register the correct chat template for our model to ensure proper prompt formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the LLaMA 3.3 chat template\n",
    "# This ensures proper formatting of prompts for the model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer to get the chat template\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/llama-3-3-70b-instruct\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.3-70B-Instruct\")\n",
    "\n",
    "# Register the chat template in our prompt registry\n",
    "# @PromptRegistry.register(\"meta-llama/Llama-3.3-70B-Instruct\")\n",
    "# @PromptRegistry.register(\"meta-llama/llama-3-3-70b-instruct\")\n",
    "@PromptRegistry.register(teacher_model)\n",
    "def llama_3_3_70b_chat_template():\n",
    "    return tokenizer.chat_template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Data Generation Pipeline\n",
    "\n",
    "Now we'll set up our Synthetic Data Generation (SDG) pipeline with the following components:\n",
    "1. SDG Flow configuration from YAML\n",
    "2. SDG Pipeline setup\n",
    "3. SDG configuration with batch processing, number of workers, and save frequency parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the flow configuration from YAML file\n",
    "# flow_cfg = Flow(client).get_flow_from_file(\"synth_knowledge1.5_llama3.3.yaml\")\n",
    "flow_cfg = Flow(client).get_flow_from_file(\"synth_knowledge1.5_llama3.3_rits.yaml\")\n",
    "\n",
    "# Initialize the SDG pipeline with processing parameters\n",
    "sdg = SDG(\n",
    "    [Pipeline(flow_cfg)],\n",
    "    num_workers=1,      # Number of parallel workers\n",
    "    batch_size=1,       # Batch size for processing\n",
    "    save_freq=1000,     # How often to save checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Seed Data\n",
    "\n",
    "We'll load our seed data (documents) that will be used to generate question-answer pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the seed data from JSON file\n",
    "# seed_data_path = \"Your seed data path\"  # Replace with your data path\n",
    "# seed_data_path = \"../instructlab/annotation/sample_data/emotion_classification.jsonl\"\n",
    "# seed_data_path = \"../instructlab/skills/sample_data/mdtable_seeds.jsonl\"\n",
    "# seed_data_path = \"../../../sample/seed_data_20250411_en.jsonl\"\n",
    "# seed_data_path = \"../../../sample/seed_data_20250411_en_2.jsonl\"\n",
    "seed_data_path = \"../../../sample/seed_data_20250411_ja.jsonl\"\n",
    "ds = load_dataset('json', data_files=seed_data_path, split='train')\n",
    "\n",
    "# For testing, we'll use just one example\n",
    "# example_index = 0\n",
    "example_index = 9\n",
    "ds = ds.select(range(example_index, example_index + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data with LLaMA 3.3\n",
    "\n",
    "Now we'll use our configured pipeline to generate synthetic question-answer pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:42:55] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> No existing checkpoints found in Tmp, generating from scratch                        <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sdg.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#107\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:42:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m No existing checkpoints found in Tmp, generating from scratch                        \u001b]8;id=214523;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\u001b\\\u001b[2msdg.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=924608;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#107\u001b\\\u001b[2m107\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Splitting the dataset into smaller batches                                           <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sdg.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#123\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Splitting the dataset into smaller batches                                           \u001b]8;id=691689;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\u001b\\\u001b[2msdg.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=724776;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#123\u001b\\\u001b[2m123\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19508.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generating dataset with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> splits, batch size <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> workers                        <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sdg.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#129\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generating dataset with \u001b[1;36m1\u001b[0m splits, batch size \u001b[1;36m1\u001b[0m, and \u001b[1;36m1\u001b[0m workers                        \u001b]8;id=333534;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\u001b\\\u001b[2msdg.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=966066;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#129\u001b\\\u001b[2m129\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Processing split <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                                    <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sdg.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#75\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">75</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Processing split \u001b[1;36m0\u001b[0m                                                                    \u001b]8;id=130973;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\u001b\\\u001b[2msdg.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=80502;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#75\u001b\\\u001b[2m75\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-3-70b-instruct/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=46200;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=804977;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-3-70b-instruct/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> LLM server supports batched inputs: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>                                         <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/llmblock.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llmblock.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/llmblock.py#36\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m LLM server supports batched inputs: \u001b[3;92mTrue\u001b[0m                                         \u001b]8;id=610117;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/llmblock.py\u001b\\\u001b[2mllmblock.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=376567;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/llmblock.py#36\u001b\\\u001b[2m36\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:44:20] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-3-70b-instruct/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:44:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=2013;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=349408;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-3-70b-instruct/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:47:58] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-3-70b-instruct/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:47:58]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=851817;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=674413;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-3-70b-instruct/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:50:28] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-3-70b-instruct/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:50:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=904791;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=552744;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-3-70b-instruct/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:54:28] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-3-70b-instruct/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:54:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=305189;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=853467;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-3-70b-instruct/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:55:04] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-3-70b-instruct/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:55:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=104857;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=636382;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-3-70b-instruct/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 36/36 [00:00<00:00, 7166.35 examples/s]\n",
      "Filter: 100%|██████████| 36/36 [00:00<00:00, 5998.53 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:55:31] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-3-70b-instruct/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:55:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=937967;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=602384;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-3-70b-instruct/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> Error converting dtype: could not convert string to float: <span style=\"color: #008000; text-decoration-color: #008000\">'Total Score: 2'</span>,  <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/filterblock.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">filterblock.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/filterblock.py#45\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">45</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         filling with <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span> to be filtered later                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m Error converting dtype: could not convert string to float: \u001b[32m'Total Score: 2'\u001b[0m,  \u001b]8;id=502933;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/filterblock.py\u001b\\\u001b[2mfilterblock.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=58447;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/filterblock.py#45\u001b\\\u001b[2m45\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         filling with \u001b[3;35mNone\u001b[0m to be filtered later                                        \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> Error converting dtype: could not convert string to float: <span style=\"color: #008000; text-decoration-color: #008000\">'Total Score: 2'</span>,  <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/filterblock.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">filterblock.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/filterblock.py#45\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">45</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         filling with <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span> to be filtered later                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m Error converting dtype: could not convert string to float: \u001b[32m'Total Score: 2'\u001b[0m,  \u001b]8;id=689685;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/filterblock.py\u001b\\\u001b[2mfilterblock.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=646031;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/filterblock.py#45\u001b\\\u001b[2m45\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         filling with \u001b[3;35mNone\u001b[0m to be filtered later                                        \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 36/36 [00:00<00:00, 2034.48 examples/s]\n",
      "Filter: 100%|██████████| 36/36 [00:00<00:00, 7685.79 examples/s]\n",
      "Filter: 100%|██████████| 34/34 [00:00<00:00, 6038.80 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:56:07] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-3-70b-instruct/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:56:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=324439;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=868176;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-3-70b-instruct/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 32/32 [00:00<00:00, 2690.97 examples/s]\n",
      "Filter: 100%|██████████| 32/32 [00:00<00:00, 6927.72 examples/s]\n",
      "Filter: 100%|██████████| 32/32 [00:00<00:00, 5869.24 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Finished future processing split <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                   <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sdg.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#149\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">149</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">          </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished future processing split \u001b[1;36m0\u001b[0m                                                   \u001b]8;id=322980;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\u001b\\\u001b[2msdg.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=761633;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#149\u001b\\\u001b[2m149\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                              \u001b[2m          \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                                                                                              \u001b[2m          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [13:11<00:00, 791.97s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data and save checkpoints\n",
    "generated_data = sdg.generate(ds, checkpoint_dir=\"Tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Mixtral Model\n",
    "\n",
    "For comparison, we'll also generate data using the Mixtral model. First, start the Mixtral server:\n",
    "\n",
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m vllm.entrypoints.openai.api_server \\\n",
    "    --model meta-llama/Llama-3.3-70B-Instruct \\\n",
    "    --dtype float16 \\\n",
    "    --tensor-parallel-size 8 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">GET</span>                                                               <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-8x7b-instruct-v01/v1/models</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mGET\u001b[0m                                                               \u001b]8;id=229622;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=500818;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-8x7b-instruct-v01/v1/models\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                  \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Mixtral model: mistralai/mixtral-8x7B-instruct-v0.1\n"
     ]
    }
   ],
   "source": [
    "# Connect to Mixtral model running on a different server\n",
    "mistral_client = OpenAI(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=endpoint_mixtral,  # Update with your Mixtral server address\n",
    "    default_headers=default_headers,\n",
    ")\n",
    "\n",
    "# Verify connection to Mixtral model\n",
    "mistral_client_teacher_model = mistral_client.models.list().data[0].id\n",
    "print(f\"Connected to Mixtral model: {mistral_client_teacher_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_mixtral = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
    "\n",
    "@PromptRegistry.register(mistral_client_teacher_model)\n",
    "def mixtral_8x7b_instruct_chat_template():\n",
    "    return tokenizer.chat_template\n",
    "\n",
    "# @PromptRegistry.register(\"text-classifier-knowledge-v3-clm\") ## ???\n",
    "# def text_classifier_knowledge_v3_clm_template():\n",
    "#     return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Mixtral Pipeline\n",
    "\n",
    "Set up a similar pipeline for Mixtral model generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create flow configuration for Mixtral\n",
    "flow_cfg_mistral = Flow(mistral_client).get_flow_from_file(\n",
    "    # \"../../src/sdg_hub/flows/generation/knowledge/synth_knowledge1.5.yaml\"\n",
    "    # \"../../src/sdg_hub/flows/generation/knowledge/synth_knowledge1.5_rits.yaml\"\n",
    "    \"synth_knowledge1.5_mixtral-8x7b_rits.yaml\"\n",
    ")\n",
    "\n",
    "# Initialize SDG pipeline for Mixtral\n",
    "sdg_mistral = SDG(\n",
    "    [Pipeline(flow_cfg_mistral)],\n",
    "    num_workers=1,\n",
    "    batch_size=1,\n",
    "    save_freq=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data with Mixtral\n",
    "\n",
    "Generate synthetic data using the Mixtral model for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> No existing checkpoints found in Tmp, generating from scratch                        <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sdg.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#107\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m No existing checkpoints found in Tmp, generating from scratch                        \u001b]8;id=456324;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\u001b\\\u001b[2msdg.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=5808;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#107\u001b\\\u001b[2m107\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Splitting the dataset into smaller batches                                           <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sdg.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#123\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Splitting the dataset into smaller batches                                           \u001b]8;id=435125;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\u001b\\\u001b[2msdg.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=925383;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#123\u001b\\\u001b[2m123\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19152.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Generating dataset with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> splits, batch size <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> workers                        <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sdg.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#129\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Generating dataset with \u001b[1;36m1\u001b[0m splits, batch size \u001b[1;36m1\u001b[0m, and \u001b[1;36m1\u001b[0m workers                        \u001b]8;id=447954;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\u001b\\\u001b[2msdg.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=501659;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#129\u001b\\\u001b[2m129\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Processing split <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                                    <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sdg.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#75\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">75</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Processing split \u001b[1;36m0\u001b[0m                                                                    \u001b]8;id=243133;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\u001b\\\u001b[2msdg.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=190333;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#75\u001b\\\u001b[2m75\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-8x7b-instruct-v01/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=453580;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=358053;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-8x7b-instruct-v01/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> LLM server supports batched inputs: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>                                         <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/llmblock.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llmblock.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/llmblock.py#36\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m LLM server supports batched inputs: \u001b[3;92mTrue\u001b[0m                                         \u001b]8;id=895095;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/llmblock.py\u001b\\\u001b[2mllmblock.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=105957;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/blocks/llmblock.py#36\u001b\\\u001b[2m36\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:56:16] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-8x7b-instruct-v01/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:56:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=29355;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=544595;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-8x7b-instruct-v01/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:56:29] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-8x7b-instruct-v01/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:56:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=770079;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=834758;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-8x7b-instruct-v01/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:56:37] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-8x7b-instruct-v01/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:56:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=987716;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=791617;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-8x7b-instruct-v01/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:56:58] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-8x7b-instruct-v01/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:56:58]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=298718;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=181090;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-8x7b-instruct-v01/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:57:08] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-8x7b-instruct-v01/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:57:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=320885;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256328;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-8x7b-instruct-v01/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 39/39 [00:00<00:00, 7298.35 examples/s]\n",
      "Filter: 100%|██████████| 39/39 [00:00<00:00, 6230.35 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:57:13] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-8x7b-instruct-v01/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:57:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=644482;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=319283;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-8x7b-instruct-v01/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 38/38 [00:00<00:00, 3139.70 examples/s]\n",
      "Filter: 100%|██████████| 38/38 [00:00<00:00, 8041.96 examples/s]\n",
      "Filter: 100%|██████████| 38/38 [00:00<00:00, 6360.59 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:57:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                                              <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">-8x7b-instruct-v01/v1/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:57:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m                                                              \u001b]8;id=323346;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=836776;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/httpx/_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[4;94m-8x7b-instruct-v01/v1/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 37/37 [00:00<00:00, 3099.76 examples/s]\n",
      "Filter: 100%|██████████| 37/37 [00:00<00:00, 7886.03 examples/s]\n",
      "Filter: 100%|██████████| 37/37 [00:00<00:00, 6327.80 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Finished future processing split <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                   <a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sdg.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#149\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">149</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">          </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finished future processing split \u001b[1;36m0\u001b[0m                                                   \u001b]8;id=64245;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py\u001b\\\u001b[2msdg.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=740888;file:///home/ryokawa/.venv/sdg_hub/lib/python3.10/site-packages/sdg_hub/sdg.py#149\u001b\\\u001b[2m149\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                              \u001b[2m          \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                                                                                              \u001b[2m          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:10<00:00, 70.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate data using Mixtral model\n",
    "generated_data_mistral = sdg_mistral.generate(ds, checkpoint_dir=\"Tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Generated Data\n",
    "\n",
    "Let's compare the outputs from both models by saving them to a markdown file for easy review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 5 examples to model_comparison.md\n"
     ]
    }
   ],
   "source": [
    "# Save comparison results to markdown file\n",
    "k = 5  # Number of examples to compare\n",
    "output_file = \"model_comparison.md\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    # Write the source document first\n",
    "    f.write(f\"### Document \\n{generated_data[0]['document']}\")\n",
    "    \n",
    "    # Compare generated Q&A pairs\n",
    "    for i in range(min(len(generated_data), len(generated_data_mistral))):\n",
    "        f.write(\"Example #{}\\n\".format(i+1))\n",
    "        \n",
    "        # LLaMA 3.3 results\n",
    "        f.write(\"### Result from llama3.3\\n\")\n",
    "        f.write(generated_data[i]['question'] + \"\\n\")\n",
    "        f.write(\"*******************************\\n\")\n",
    "        f.write(generated_data[i]['response'] + \"\\n\")\n",
    "        f.write(\"=================================\\n\")\n",
    "        \n",
    "        # Mixtral results\n",
    "        f.write(\"### Result from mistral\\n\") \n",
    "        f.write(generated_data_mistral[i]['question'] + \"\\n\")\n",
    "        f.write(\"*******************************\\n\")\n",
    "        f.write(generated_data_mistral[i]['response'] + \"\\n\")\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "print(f\"Wrote {k} examples to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Usage\n",
    "\n",
    "For large-scale data generation, use the command-line script instead of this notebook:\n",
    "\n",
    "```bash\n",
    "python scripts/generate.py --ds_path seed_data.jsonl \\\n",
    "    --bs 2 --num_workers 10 \\\n",
    "    --save_path <your_save_path> \\\n",
    "    --flow ../src/sdg_hub/flows/generation/knowledge/synth_knowledge1.5.yaml \\\n",
    "    --checkpoint_dir <your_checkpoint_dir> \\\n",
    "    --endpoint <your_endpoint>\n",
    "```\n",
    "\n",
    "Note: For LLaMA 3.3, use `synth_knowledge1.5_llama3.3.yaml` as the flow configuration file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdg_hub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
